---
title: "R Notebook"
output: github_document


---
title: "R Notebook"
```{r}
library(gitcreds)
gitcreds_set()
```
## Installing DADA2 Package
```{r}
library(dada2); packageVersion("dada2")
```
#In this line we indicate rstudio that we want to work with the external package DADA2

##Importing the documents.
#In terminal type wget and unzip 

```{r}
path <- "/home/rstudio/DADA2/MiSeq_SOP"
list.files(path)
```
#We named the path to specify a folder where the files that you want to list are located
#The list.files() function is to return a vector containing all the files names that are in our path
#One file represents one sample with its respective primer used. In one file more than one sequences (reads) will be present but of the same length but of different quality. Some read will be unique while some reads will be variances or sequencing errors.

##Matching lists of the forward and reverse fastq files
```{r}
fnFs <- sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1) #Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
```
#We use the list.files() function to find all files within the “path” that have the pattern “R1_001.fastq” in their name. The full.names = TRUE argument ensures that the full path to each file is included in the returned vector. The result is stored in the variable fnFs \#This is extracting sample names: We use the sapply() function to apply the strsplit() function to each element in the fnFs vector. strsplit() splits each file name based on the underscore character. The first element of each split is extracted using \[, 1\], and the resulting vector of sample names is stored in the variable sample.names.

##Inspect read quality profiles
#To inspect Inspect read (forward and reverse) quality profiles
```{r}
plotQualityProfile(fnFs[1:2]) 
#Visualizing the quality profiles of the forward reads
```

```{r}
plotQualityProfile(fnRs[1:2]) #Visualizeing the quality profile of the reverse reads
```
#[1:2] means sample. We can view all the samples quality profile as well

##Filter and Trim
#Based on these profiles, we will truncate the reverse reads at position 160 where the quality distribution crashes. Reads must still overlap after truncation in order to merge them later.
```{r}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz")) #Place filtered files in filtered/subdirectory
names(filtFs) <- sample.names
names(filtRs) <- sample.names
```
```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,160),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=FALSE)
head(out)
```
#The filterAndTrim() function from the DADA2 package is being used to filter and trim the fastq files. This step removes low-quality reads and trims the reads to a specific position.
#reads.in: The number of reads in the original file.
#reads.out: The number of reads that passed the filtering and trimming steps.
#fnFs: A vector of file names for the forward reads.
#filtFs: A vector of file names for the filtered forward reads.
#fnRs: A vector of file names for the reverse reads.
#filtRs: A vector of file names for the filtered reverse reads.
#truncLen: A vector of two integers specifying the truncation lengths for the forward and reverse reads, respectively. In this case, the forward reads will be truncated to 240 base pairs and the reverse reads will be truncated to 160 base pairs.
#The filterAndTrim() function performs the following steps: 1)Filters reads: It removes low-quality reads based on their quality scores. 2)Trims reads: It trims the reads to the specified truncation lengths. 3) Writes filtered reads: It writes the filtered reads to the files specified in filtFs and filtRs.


##Learn the Error Rates
#Error rate refers to the estimated rate at which sequencing errors occur in the raw sequencing data. These errors can arise from various factors, such as instrument noise, chemical reactions, and sample preparation issues.
```{r}
errF <- learnErrors(filtFs, multithread=TRUE)
```
```{r}
errR <- learnErrors(filtRs, multithread=TRUE)
```
#The learnErrors() function estimates the error rates for each base position in the filtered reads. This information is used by DADA2 to denoise the data and assign reads to OTUs.
#multithread=TRUE: This argument specifies that the function should use multiple threads to speed up the computation.

##Visualization of the estimated error rates
```{r}
plotErrors(errF, nominalQ=TRUE)
```

##Sample Inference Analysis
```{r}
dadaFs <- dada(filtFs, err=errF, multithread=TRUE)
```
```{r}
dadaRs <- dada(filtRs, err=errR, multithread=TRUE)
```
#Ssample inference in DADA2 refers to the process of analyzing sequence data to identify and quantify unique biological sequences (OTUs or ASVs) within a sample. It's a crucial step in understanding the microbial diversity present in a given environment.
#Sample ID: Each row represents a different sample.
#Reads: The total number of sequencing reads obtained for that sample.
#Unique sequences: The number of distinct DNA sequences identified within the sample.
#This information provides a basic overview of the sequencing depth and diversity observed in each sample.
#The results obtained mean that for each sample (example sample 1, forward) there are 7113 reads (sequences) in which 1979 are unique sequences (that is occur only once) \#The more a species will be present in the sample the more its sequence will be present in the sequencing results. Variance of this species will be considered as other sequences and will form their own OTU.

##Inspecting the returned dada-class object:
```{r}
dadaFs[[1]]
```
# 1979 input unique sequences: Refers to the total number of unique DNA sequences that were initially identified in the sample after filtering and trimming.
#128 sequence variants: DADA2 grouped these unique sequences into 128 clusters based on their similarity and the estimated error rates. Each cluster represents a unique biological sequence.

##Merge paired reads
#Merge the forward and reverse reads together to obtain the full denoised sequences (constructing the merged “contig” sequences). By default, merged sequences are only output if the forward and reverse reads overlap by at least 12 bases, and are identical to each other in the overlap region (these conditions can be changed via function arguments).
```{r}
mergers <- mergePairs(dadaFs, filtFs, dadaRs, filtRs, verbose=TRUE)
# Inspect the merger data.frame from the first sample
head(mergers[[1]])
```
```{r}
head(mergers[[1]])
```

##Construct sequence table
#construct an amplicon sequence variant table (ASV) table, a higher-resolution version of the OTU table produced by traditional methods.
```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab)
```
```{r}
# Inspect distribution of sequence lengths
table(nchar(getSequences(seqtab)))
```

#The sequence table is a matrix with rows corresponding to (and named by) the samples, and columns corresponding to (and named by) the sequence variants. This table contains 293 ASVs, and the lengths of our merged sequences all fall within the expected range for this V4 amplicon
#The sequence table summarizes the identified unique sequences (ASVs) and their abundance in the sample. It provides a fundamental overview of the microbial diversity and composition.

##Remove chimeras
```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
dim(seqtab.nochim)
```
```{r}
sum(seqtab.nochim)/sum(seqtab)
```

##Tracking reads through the pipeline
#look at the number of reads that made it through each step in the pipeline
```{r}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))
# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
```
#Input: The total number of reads originally present in the sample before any processing. #Filtered: The number of reads remaining after filtering out low-quality reads based on quality scores. #Denoisedf: The number of reads remaining after denoising the forward reads (using the estimated error rates). \#Denoisedr: The number of reads remaining after denoising the reverse reads (using the estimated error rates).
#Merged: The number of reads that were successfully merged from paired-end sequencing data (if applicable). \#Nonchim: The number of reads that were not assigned to any chimeric sequence (potential artifacts resulting from PCR errors).

##Assign taxonomy
```{r}
taxa <- assignTaxonomy(seqtab.nochim, "/home/rstudio/DADA2_final/silva_nr99_v138.1_train_set.fa.gz?download=1", multithread=TRUE)
```

#inspect the taxonomic assignments:
```{r}
taxa.print <- taxa # Removing sequence rownames for display only
rownames(taxa.print) <- NULL
head(taxa.print)
```
##Evaluating Accuracy

```{r}
unqs.mock <- seqtab.nochim["Mock",]
unqs.mock <- sort(unqs.mock[unqs.mock>0], decreasing=TRUE) # Drop ASVs absent in the Mock
cat("DADA2 inferred", length(unqs.mock), "sample sequences present in the Mock community.\n")
```
#A mock community is a synthetic mixture of known strains of bacteria. It serves as a controlled experiment because the exact composition is known, allowing for direct comparison between the inferred results and the ground truth. By comparing the inferred sequence variants from the mock community to the expected composition, we can evaluate how well DADA2 performs in terms of identifying and quantifying different bacterial species.

#The evaluation aims to determine the accuracy of DADA2 in identifying the correct sequence variants and their abundances. Error rate calculation: By comparing the inferred results to the known composition of the mock community, the error rate of the DADA2 pipeline can be calculated. The results obtained from the evaluation can be compared to those of other microbiome analysis methods to assess DADA2’s performance relative to other tools.
```{r}
mock.ref <- getSequences(file.path(path, "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```
#This mock community contained 20 bacterial strains. DADA2 identified 20 ASVs all of which exactly match the reference genomes of the expected community members. The residual error rate after the DADA2 pipeline for this sample is 0%.

###Phyloseq analysis
#phyloseq is an R package designed to make microbiome analysis and visualization easier. It provides a framework for importing, manipulating, and analyzing microbiome data, such as sequencing data.

##Import Phyloseq
```{r}
library(phyloseq); packageVersion("phyloseq")
```
```{r}
library(Biostrings); packageVersion("Biostrings")
```
```{r}
library(ggplot2); packageVersion("ggplot2")
```
```{r}
theme_set(theme_bw())
```

## Construction of a simple sample data.frame from the information encoded in the filenames
```{r}
samples.out <- rownames(seqtab.nochim)
subject <- sapply(strsplit(samples.out, "D"), `[`, 1)
gender <- substr(subject,1,1)
subject <- substr(subject,2,999)
day <- as.integer(sapply(strsplit(samples.out, "D"), `[`, 2))
samdf <- data.frame(Subject=subject, Gender=gender, Day=day)
samdf$When <- "Early"
samdf$When[samdf$Day>100] <- "Late"
rownames(samdf) <- samples.out
```
#The theme_set(theme_bw()) function in R's ggplot2 package sets the default theme for all subsequent plots to the "bw" theme. This theme is characterized by a white background, black text, and a minimalist aesthetic


##now construct a phyloseq object directly from the dada2 outputs.
```{r}
ps <- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf), 
               tax_table(taxa))
ps <- prune_samples(sample_names(ps) != "Mock", ps) # Remove mock sample
```

```{r}
dna <- Biostrings::DNAStringSet(taxa_names(ps))
names(dna) <- taxa_names(ps)
ps <- merge_phyloseq(ps, dna)
taxa_names(ps) <- paste0("ASV", seq(ntaxa(ps)))
ps
```
#end of data preparation for phyloseq analysis. Now we proceed with the phyloseq analysis.


##Visualize alpha-diversity:
```{r}
plot_richness(ps, x="Day", measures=c("Shannon", "Simpson"), color="When")
```
#No obvious systematic difference in alpha-diversity between early and late samples

##Ordination:
#Ordination is a statistical technique used to visualize the relationships between samples or objects based on their similarity or dissimilarity. It is used in ecology to understand the structure and patterns within a dataset. For microbiome analysis, ordination is used to visualize the differences between microbial communities. By plotting the samples in a low-dimensional space, ordination can help identify groups of samples with similar microbial compositions and reveal the underlying factors driving these differences.
```{r}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- transform_sample_counts(ps, function(otu) otu/sum(otu))
ord.nmds.bray <- ordinate(ps.prop, method="NMDS", distance="bray")
```

```{r}
plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```
##BarPlot
```{r}
top20 <- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]
ps.top20 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top20 <- prune_taxa(top20, ps.top20)
plot_bar(ps.top20, x="Day", fill="Family") + facet_wrap(~When, scales="free_x")
```
